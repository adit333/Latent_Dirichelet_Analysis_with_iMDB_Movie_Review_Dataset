{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latent Dirichlet Allocation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Topic modeling is the task of assigning each document to one or multiple topics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### LDA model tries to find groups of words (the topics) that appear together frequently. LDA also requires that each document can be understood as a “mixture” of a subset of the topics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use a dataset of movie reviews from the IMDb website collected by Andrew Maas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is provided as text files in two separate folders,\n",
    "one for the training data and one for the test data. Each of these in turn has two subfolders,\n",
    "one called pos and one called neg. The pos folder contains all the positive reviews, each as a separate text file, and similarly for the neg folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the helper function in scikit-learn to load files stored\n",
    "in such a folder structure, called load_files. We apply the load_files function first to the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type of text_train: <class 'list'>\n",
      "length of text_train: 25000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import load_files\n",
    "\n",
    "reviews_train = load_files(\"aclImdb/train/\")\n",
    "# Load_files returns a bunch, containing training texts and training labels\n",
    "text_train, y_train = reviews_train.data, reviews_train.target\n",
    "\n",
    "print(\"type of text_train: {}\".format(type(text_train)))\n",
    "print(\"length of text_train: {}\".format(len(text_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s apply LDA to our movie review dataset. For unsupervised text document models, it is good to remove very common words, as they might otherwise dominate the analysis. We’ll remove words that appear in at\n",
    "least 15 percent of the documents, and we’ll limit the bag-of-words model to the\n",
    "10,000 words that are most common after removing the top 15 percent:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1 (10 topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer(max_features=10000, max_df=.15)\n",
    "X = vect.fit_transform(text_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will learn a topic model with 10 topics. We’ll use the\n",
    "\"batch\" learning method, which is somewhat slower than the default (\"online\") but\n",
    "usually provides better results, and increase \"max_iter\", which can also lead to better\n",
    "models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "lda = LatentDirichletAllocation(n_components=10, learning_method=\"batch\",\n",
    "                                max_iter=25, random_state=0)\n",
    "# We build the model and transform the data in one step\n",
    "# Computing transform takes some time,\n",
    "# and we can save time by doing both at once\n",
    "document_topics = lda.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### LatentDirichletAllocation has a components_ attribute that stores how important each word is for each topic. The size of components_ is (n_topics, n_words):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 10000)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.components_.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To understand better what the different topics mean, we will look at the most important\n",
    "words for each of the topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic 0       topic 1       topic 2       topic 3       topic 4       \n",
      "--------      --------      --------      --------      --------      \n",
      "guy           show          horror        family        action        \n",
      "gets          series        killer        years         effects       \n",
      "around        episode       house         saw           original      \n",
      "girl          tv            murder        book          animation     \n",
      "car           episodes      wife          old           special       \n",
      "down          shows         night         children      fight         \n",
      "sex           season        thriller      kids          game          \n",
      "woman         television    death         now           fi            \n",
      "women         new           creepy        again         sci           \n",
      "girls         funny         dead          young         look          \n",
      "\n",
      "\n",
      "topic 5       topic 6       topic 7       topic 8       topic 9       \n",
      "--------      --------      --------      --------      --------      \n",
      "music         didn          us            war           role          \n",
      "song          thing         world         american      cast          \n",
      "songs         nothing       between       world         performance   \n",
      "rock          worst         director      documentary   comedy        \n",
      "dance         funny         own           history       actors        \n",
      "oscar         actually      work          black         play          \n",
      "new           actors        may           us            actor         \n",
      "girl          re            without       white         performances  \n",
      "musical       10            seems         years         played        \n",
      "singing       minutes       real          country       plays         \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# For each topic (a row in the components_), sort the features (ascending)\n",
    "# Invert rows with [:, ::-1] to make sorting descending\n",
    "sorting = np.argsort(lda.components_, axis=1)[:, ::-1]\n",
    "\n",
    "# Get the feature names from the vectorizer\n",
    "feature_names = np.array(vect.get_feature_names())\n",
    "\n",
    "import mglearn\n",
    "# Print out the 10 topics:\n",
    "mglearn.tools.print_topics(topics=range(10), feature_names=feature_names, sorting=sorting, topics_per_chunk=5, n_words=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topic 1 seems to be about historical and war movies,\n",
    "topic 2 might be about bad comedies, topic 3 might be about TV series. Topic 4\n",
    "seems to capture some very common words, while topic 6 appears to be about children’s\n",
    "movies and topic 8 seems to capture award-related reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Using only 10 components (topics), each of the topics needs to be very broad, so that they can together cover all the different kinds of reviews in our dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let us build a model with 100 components."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2 (100 topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### With 100 topics, each topic can specalise more to get more interesting features of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LDA with 100 components/topics\n",
    "lda100 = LatentDirichletAllocation(n_components=100, learning_method=\"batch\",max_iter=25, random_state=0, n_jobs=-1)\n",
    "\n",
    "# Transforming the dataset\n",
    "document_topics100 = lda100.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 100)\n"
     ]
    }
   ],
   "source": [
    "print(document_topics100.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The documets_topics100 contains the 25000 training samples(reviews) represented by 100 components(topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 10000)\n"
     ]
    }
   ],
   "source": [
    "print(lda100.components_.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows that the 100 components/topics were identified and each have 10000 most relevant and frequent words for that topic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Let us see at only some of the 100 topics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic 7       topic 16      topic 24      topic 25      topic 28      topic 36      topic 37      \n",
      "--------      --------      --------      --------      --------      --------      --------      \n",
      "us            romantic      horror        years         effects       jeff          lady          \n",
      "our           jack          gore          old           special       anderson      french        \n",
      "world         romance       zombie        ago           fi            simon         julia         \n",
      "lives         comedy        scary         early         sci           beach         kelly         \n",
      "own           danny         blood         later         space         wave          leading       \n",
      "human         hotel         slasher       saw           monster       surfing       american      \n",
      "each          perfect       dead          today         science       lose          beautiful     \n",
      "may           kubrick       zombies       year          alien         magazine      julie         \n",
      "real          nicholson     killer        few           look          young         leslie        \n",
      "society       shining       effects       late          cgi           big           paris         \n",
      "reality       charming      pretty        now           fiction       run           garbo         \n",
      "different     wonderful     flick         remember      robot         friends       dance         \n",
      "person        sally         genre         came          giant         sidney        actress       \n",
      "live          sports        night         since         creature      riding        girl          \n",
      "understand    chess         original      70            aliens        canadian      sequence      \n",
      "self          beautiful     death         days          scientist     roller        romantic      \n",
      "without       wendy         isn           seems         planet        coaster       before        \n",
      "point         sweet         fun           times         channel       ride          nicole        \n",
      "cannot        comedies      fans          30            cheesy        sport         ballet        \n",
      "true          robert        budget        20            earth         cattle        dancing       \n",
      "\n",
      "\n",
      "topic 45      topic 51      topic 53      topic 54      topic 63      topic 89      topic 97      \n",
      "--------      --------      --------      --------      --------      --------      --------      \n",
      "mr            motion        performance   stage         tale          paris         book          \n",
      "emma          picture       performances  welles        cinderella    festival      read          \n",
      "mrs           computer      excellent     broadway      fairy         13            didn          \n",
      "bush          hip           beautiful     dance         ball          dentist       am            \n",
      "kate          taylor        young         cagney        disney        pg            thought       \n",
      "paltrow       real          between       dancing       lane          pet           saw           \n",
      "austen        slow          wonderful     kane          scarecrow     short         wasn          \n",
      "spielberg     big           superb        lady          irish         louis         original      \n",
      "anne          now           amazing       citizen       frankie       wife          fan           \n",
      "ho            close         brilliant     dancers       classic       directors     liked         \n",
      "betty         hop           role          orson         lester        saw           felt          \n",
      "brendan       pictures      truly         warner        magical       screening     found         \n",
      "miss          university    actors        chorus        gypo          french        got           \n",
      "jeremy        going         true          line          parsons       segment       sure          \n",
      "half          gas           cast          shanghai      tales         stories       lot           \n",
      "color         skull         every         musical       phil          rat           ending        \n",
      "bates         hepburn       both          play          mclaglen      segments      watched       \n",
      "gwyneth       hollywood     makes         production    lucille       rats          part          \n",
      "knightley     audrey        feel          michael       mice          couple        done          \n",
      "kells         once          heart         hara          ford          le            feel          \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Chosen topics\n",
    "topics = np.array([7, 16, 24, 25, 28, 36, 37, 45, 51, 53, 54, 63, 89, 97])\n",
    "\n",
    "# For each topic (a row in the components_), sort the features (ascending)\n",
    "# Invert rows with [:, ::-1] to make sorting descending\n",
    "sorting = np.argsort(lda100.components_, axis=1)[:, ::-1]\n",
    "feature_names = np.array(vect.get_feature_names())\n",
    "\n",
    "# Print the chosen topics\n",
    "mglearn.tools.print_topics(topics=topics, feature_names=feature_names,sorting=sorting, topics_per_chunk=7, n_words=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The topics we extracted this time seem to be more specific, though many are hard to\n",
    "interpret. Topic 7 seems to be about horror movies and thrillers; topics 16 and 54\n",
    "seem to capture bad reviews, while topic 63 mostly seems to be capturing positive\n",
    "reviews of comedies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, topic 45 seems to be about music. Let’s check which kinds of reviews are assigned to this topic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'The script is nice.Though the casting is absolutely non-watchable.\\n'\n",
      "b'Jane Austen would definitely approve of this one!<br /><br />Gwyneth Paltrow does an awesome job capturing the attitude of Emma. She is funny without being excessively silly, yet elegant.\\n'\n",
      "b'I have no idea how a Texan (the director, Douglas McGrath) and the American actress Gwyneth Paltrow ever pulled this off but seeing this again will remind you what all the fuss about Ms. Paltrow was in the first place! I had long since gone off the woman and still feel she is rather dull in her Oscar-winning \"Shakespeare In Love\" performance but she gets all the beats right here--she is nigh on perfect as Emma Woodhouse.\\n'\n",
      "b\"While there aren't any talking animals, big lavish song production numbers, or villians with half white / half black hair ..\\n\"\n",
      "b\"While there aren't any talking animals, big lavish song production numbers, or villians with half white / half black hair ..\\n\"\n",
      "b'The Color Purple is a masterpiece. It displays the amazing acting abilities of Whoopi Goldberg, Oprah Winfrey, and Danny Glover.\\n'\n",
      "b'I\\'ve always been enthusiastic about period dramas, an art form in which the BBC has excelled in the past. This presentation of \"Byron\" was unbelievable.\\n'\n",
      "b\"Kate Beckinsale is as good if not better than Gwyneth Paltrow as Emma in this movie, although I really liked Gwyneth Paltrow in the other Emma version. They're both good in different ways.\\n\"\n",
      "b'I was about thirteen when this movie came out on television. It is far superior in action than most movies since.\\n'\n",
      "b'This agonizing comedy-drama got surprisingly sterling reviews upon its release in 1979. I remember opening the movie-section of the L.\\n'\n"
     ]
    }
   ],
   "source": [
    "# Sort by weight of \"music\" i.e topic 45\n",
    "music = np.argsort(document_topics100[:, 45])[::-1]\n",
    "\n",
    "# Print the five documents where the topic is most important\n",
    "for i in music[:10]:\n",
    "    # Show first two sentences\n",
    "    print(b\".\".join(text_train[i].split(b\".\")[:2]) + b\".\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, this topic covers a wide variety of music-centered reviews, from musicals,\n",
    "to biographical movies."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
